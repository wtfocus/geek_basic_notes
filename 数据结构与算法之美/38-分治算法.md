[TOC]

## 38 | 分治算法：谈一谈大规模计算框架 MapReduce 中的分治思想

1.  理解 MapReduce 的算法思想 -- **分治算法**

### 分治算法

1.  概念
    -   核心思想：分而治之，
    -   就是将原问题划分成 n 个**规模较小**，并且结构与原**问题相似**的子问题。**递归**地解决这些子问题，然后再**合并**其结果，就得到原问题的解。
2.  分治 vs 递归
    -   分治算法是一种处理问题的**思想**
    -   递归是一种**编程技巧**。
3.  实现步骤
    1.  分解，
        -   将原问题分解成一系列的子问题。
    2.  解决，
        -   递归地求解各个子问题，若子问题足够小，则直接求解。
    3.  合并，
        -   将子问题的结果合并成原问题。
4.  适用场景
    1.  原问题与分解成的小问题具有**相同的模式**。
    2.  原问题分解成的子问题可以独立求解，子问题之间**没有相关性**
    3.  具有**分解终止条件**，也就是说，当问题足够小时，可以直接求解。
    4.  可以将子问题合并成原问题，并且**子问题合并的代价不能太大**

### 应用举例

1.  如何编程求出一组数据的有序对个数或者**逆序对个数**呢？

    -   图解

        -   ![img](imgs/e835cab502bec3ebebab92381c667532.jpg)

    -   代码

        -   ```java
            private int num = 0; // 全局变量或者成员变量
            
            public int count(int[] a, int n) {
              num = 0;
              mergeSortCounting(a, 0, n-1);
              return num;
            }
            
            private void mergeSortCounting(int[] a, int p, int r) {
              if (p >= r) return;
              int q = (p+r)/2;
              mergeSortCounting(a, p, q);
              mergeSortCounting(a, q+1, r);
              merge(a, p, q, r);
            }
            
            private void merge(int[] a, int p, int q, int r) {
              int i = p, j = q+1, k = 0;
              int[] tmp = new int[r-p+1];
              while (i<=q && j<=r) {
                if (a[i] <= a[j]) {
                  tmp[k++] = a[i++];
                } else {
                  num += (q-i+1); // 统计 p-q 之间，比 a[j] 大的元素个数
                  tmp[k++] = a[j++];
                }
              }
              while (i <= q) { // 处理剩下的
                tmp[k++] = a[i++];
              }
              while (j <= r) { // 处理剩下的
                tmp[k++] = a[j++];
              }
              for (i = 0; i <= r-p; ++i) { // 从 tmp 拷贝回 a
                a[p+i] = tmp[i];
              }
            }
            
            ```

        -   

### 大数据处理中的应用

1.  需求背景
    -   给 10 GB 的订单文件按照金额排序。
2.  需求分析
    -   难点：数据量太大，无法一次加载到内存，也就无法通过单纯地使用快排、归并基础算法来解决了。
3.  解决思路
    -   这里利用分治思想。
    -   先将海量数据集合划分为多个小的数据集合，每个小的数据集合单独加载到内存来解决。
    -   然后再将排序后的小数据集合合并成大数据集合。
4.  注意点
    -   **网络开销**不能太大

