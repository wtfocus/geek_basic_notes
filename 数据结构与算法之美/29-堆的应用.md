[TOC]

## 29 | 堆的应用：如何快速获取到 Top 10 最热门的搜索关键词？

1.  开篇题：
    -   现在我们有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到热门榜 **Top 10** 的搜索关键词呢？

### 优先级队列

1.  优先级队列
  
    -   在优先级队列中，数据的出队顺序是按照优先级来，**优先级最高的，最先出队。**
2.  如何实现一个优先级队列呢？
    -   方法有很多，但是用堆来实现是**最直接、最高效**的。
    -   一个堆就可以看作是一个优先级队列。
        -   往优先级队列中**插入**一个元素，就相当于往堆中插入一个元素。
        -   从优先级队列中**取出**优先级最高的元素，就相当于取出堆顶元素。

#### 合并有序小文件

1.  需求：
    -   假设，我们有 100 个小文件，每个文件大小是 100MB，每个文件中存储的都是有序字符串。
    -   我们希望将这些 100 个小文件合并成一个有序的大文件。
  
2.  初步思路
    -   类似归并排序中的合并函数。
    -   我们从 100 个文件中，各取第一个字符串，放入**数组**中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。
3.  思考
    -   这里，我们用**数组**这种数据结构，来存储从小文件中取出来的字符串。每次从数组中取最小字符串，都需要循环遍历整个数组。时间复杂度为　`O(n)`。显然，不是很高效。
    -   有没有更加高效的方法呢？

4.  优化思路
    -   这里就可以用到**优先级队列，也可以说是堆**。
    -   我们将从小文件中取出来的字符串放入到**小顶堆**中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。
    -   我们将**堆顶**的元素的字符串放入到大文件中，并将其从堆中删除。
    -   然后，再从小文件中取出下一个字符串，放入堆中。
    -   循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。
5.  小结
    -   **删除**堆顶数据和往堆中**插入**数据的时间复杂度都是 `O(logn)`，n 表示堆中的数据个数。

#### 高性能定时器

1.  需求
    -   假设，我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。
2.  初步思路
    -   **无限轮循**，定时器每过一个很小的单位时间（如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。
    -   ![img](imgs/b04656d27fd0ba112a38a28c892069e7-6649757.jpg)
3.  思考
    -   无限轮循的做法比较低效，主要原因有两点：
        1.  **无效扫描**次数巨多。任务的约定执行时间离当前可能还要很久，这样，前面很多次扫描，其实都是徒劳。
        2.  **全表**扫描。每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。
4.  优化思路
    -   我们就可以用**优先级队列**来解决。
    -   我们按照任务设定的执行时间，**将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。**
    -   定时器就不需要每隔 1 秒，就扫描一遍任务列表了。**它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。**
    -   **这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。**这样，定时器就可以设定在 T 秒后，再来执行任务。从当前时间点到 （T-1）秒，这段时间里，定时器都不需要作任何事情。
    -   当 T 秒时间过去后，定时器取优先级队列中队首的任务执行。然后，再计算新的队首任务的执行时间点与当前时间点的差值 ，把这个值作为定时器执行下一个任务需要等待的时间。
    -   这样，定时器就不用每间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。

### 利用堆求 Top K

1.  需求
	-   这个问题可以抽象成两类：
		1.  针对**静态数据**集合，
		2.  针对**动态数据**集合
2.  实现思路
    1.  针对**静态数据**，如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？
        -   我们可以维护一个**大小为 K 的小顶堆** ，顺序**遍历**数组，从数组中取出数据与**堆顶**元素比较。
        -   如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中。
        -   如果比堆顶元素小，则不做处理，继续遍历数组。
        -   这样，等数组中的数据遍历完之后，堆中的数据就是前 K 大数据了。
        -   **遍历**数组需要 O(n) 的时间复杂度，一次**堆化**操作需要 O(logK)的时间复杂度，所以，**最坏**情况下，n个元素都入堆一次，时间复杂度就是 O(nlogK)。
    2.  针对**动态数据**，求得 Top K 就是实时 Top K。怎么理解？
        -   一个数据集合中的两个操作
            -   添加数据
            -   询问当前的前 K 大数据
        -   实际上，我们可以**维护一个 K 大小的小顶堆**，当有数据被添加到集合中时，我们就拿它与**堆顶**的元素对比。
        -   如果比堆顶元素大，我们就把堆顶元素删除，并且，将这个元素插入到堆中。
        -   如果比堆顶元素小，则不做处理。
        -   这样，无论任何时间需要查询当前的前 K 大数据，我们都可以立刻返回给他。时间复杂度为　O(1)。

### 利用堆求中位数

1.  需求
    
	-   如何求**动态**数据集合**中位数**。
    
2.  背景概要

    -   中位数
        -   就是处在中间位置的那个数。
        -   **奇数**情况，把数据从小到大排列，那第 n/2 + 1 个数据就是中位数。
        -   **偶数**情况，那处于中间位置的数据有两个，第 n/2 个和 第 n/2 + 1 个数据。这时，我们可以随意取一个作为中位数，
        -   ![img](imgs/1809157fdd804dd40a6a795ec30acbb6-6650307.jpg)

3.  实现思路

    -   **静态**数据集合
        -   中位数是**固定**的，我们可以先排好序，第 n/2 个数据就是中位数。
        -   每次询问中位数的时候，我们直接返回这个固定的值就好了。
        -   尽管排序的代价比较大，但，边际成本会很小。
    -   **动态**数据集合
        -   中位数在不停的变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。

4.  优化思路（**动态**数据集合）

    -   我们可以维护两个堆 
        -   一个**大顶堆**，存储**前半部分**数据
        -   一个**小顶堆**，存储**后半部分**数据
        -   小顶堆中的数据都**大于**大顶堆中的数据。
        
    -   如果 n 是**偶数**
        -   那前 n/2 个数据存储在大顶堆中，后 n/2 个数据存储在小顶堆中。
        -   这样，大顶堆中的堆顶元素，就是我们要找的中位数。
        
    -   如果 n 是**奇数**，情况是类似的。

        -   大顶堆就存储 n/2 + 1 个数据，小顶堆中就存储 n/2 个数据。

        -   ![img](imgs/08c29d3e014a4baf5f8148c2271e6099-6650464.jpg)

    -   注意：

        >   当**新添加**一个数据的时候，就有可能出现，两个堆中的数据个数**不符合**前面约定的情况。那么我们就需要调整两个堆，让大顶堆中的堆顶元素继续是中位数。
        
    -   复杂度分析
    
        -   **插入**数据因为需要涉及堆化，所以，时间复杂度就变成了 **O(logn)**
        -   但是，**求中位数**我们只需要返回大顶堆的堆顶元素就可以了，时间复杂度是 **O(1)**。

### 解答开篇

1.  开篇题

    -   如何在一个包含 10 亿个搜索关键词的日志文件中，快速获取到 **Top 10** 最热门的搜索关键词呢?

    -   限制场景：单机，内存 1GB。

2.  解决方案

    1.  使用**散列表**统计出每个搜索关键词出现的频率。
    2.  维护一个大小为 10 的**小顶堆**，遍历散列表，依次与堆顶元素比较每个搜索关键词出现的次数。

3.  思考

    -   如果单机内存无法存储所有搜索关键词，则可以利用**哈希分片**算法。先拆分成多个小文件，再计算，最后合并计算结果，求出 Top 10。

### 课后思考

1.  一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 新闻摘要，滚动显示在网站首页上，并且，每隔 1 小时更新一下。如果你是负责开发这个功能的工程师，你会如何实现？

### 精选留言

1.  feifei

    >   1.  对每篇新闻摘要计算一个 hashcode，并建立摘要与 hashcode 的关联关系，使用 map 存储以 hashcode 为 key ，新闻摘要为值。
    >
    >   2.  按每小时一个文件的方式记录下被点击的摘要的 hashcode。
    >
    >   3.  当一个小结束后，上一个小时的文件被关闭，开始计算上一个小时的点击 Top 10。
    >
    >   4.  将 hashcode 分片到多个文件中，通过对 hashcode 取模运算，即可将相同的 hashcode 分片到相同的文件中。
    >
    >   5.  针对每个文件取 Top 10 的 hashcode，使用 `Map<hashcode, int>` 的方式，统计出所有摘要点击次数，然后，再使用小顶堆（大小为 10）计算 Top 10。
    >
    >   6.  再针对所有分片计算一个总的 Top 10，最后合并的逻辑也是使用小顶堆，计算 Top 10。
    >
    >   7.  如果仅展示前一小时的 Top 10，计算结束。
    >
    >   8.  如果需要展示全天，需要与上一次的计算按 hashcode 进行合并，然后，再在这个合并的数据中取 Top 10。
    >
    >   9.  在展示时，将计算得到的 Top 10 的 hashcode转化为新闻摘要，显示即可。




