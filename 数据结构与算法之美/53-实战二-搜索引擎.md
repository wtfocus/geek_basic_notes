[TOC]

## 53 | 算法实战（二）： 剖析搜索引擎背后的经典数据结构和算法

1. 开篇题
	- 剖析**搜索引擎**背后的数据结构和算法。

### 整体介绍

1. **搜集**
	- 利用爬虫爬取网页
2. **分析**
	- 负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作
3. **索引**
	- 通过临时索引，构建倒排索引
4. **查询**
	- 响应用户请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果。

### 搜集

- 搜索引擎把整个互联网看作数据结构中的**有向图**，把每个页面看作一个顶点。如果某个页面上包含另一个页面的链接，那我们就在两个顶点间连一条有向边。
- 搜索引擎采用的是**广度优先搜索策略**。（原理）

#### 待抓取网页链接文件：links.bin

- 在爬取网页的过程中，爬虫会不停的解析页面链接，将其放到队列中。内存是相对有限的。
- **我们用一个存储在磁盘中的文件（links.bin）来作为队列**。爬虫将网页解析出来的链接直接存储到 links.bin 文件中。
- 这样用文件的方法来存储网页链接的方式，还有其他好处。如，支持断点续爬。

#### 网页判重文件： bloom_filter.bin

- 使用**布隆过滤器**，我们就可以快速并且非常节省内存地实现网页的判重。
- 不过，还是刚刚那个问题，如果我们把布隆过滤器存储在内存中，一旦机器宕机重启后，布隆过滤器就被清空了。这样就可能导致大量已经爬取的网页会被重复爬取。
- 如果解决这个问题呢？
    - 我们可以**定期**的将布隆过滤器**持久化**到磁盘中，存储在 bloomfilter.bin 文件中。

#### 原始网页存储文件：doc_raw.bin

- 爬取到网页后，我们需要将其存储下来，以备后面离线分析、索引用之用。
- **我们可以把多个网页存储在一个文件中。每个网页通过一定的标识进行分隔，方便后续读取。**如下图：
    - ![img](imgs/195c9a1dceaaa9f4d2483fa91455404d-5018604.jpg)
- **我们也要对文件大小做一定的限制**。如，每个文件不能超过 1GB，当超过的时候，我们就创建一个新文件。

#### 网页链接及其编号的对应文件：doc_id.bin

- 网页编号实际上就是给每个网页分配的一个唯一的 ID，方便我们后续对网页进行分析、索引。
- 在存储网页的同时，我们将**网页链接跟编号**之间的对应关系，存储在另一个 doc_id.bin 文件中。

#### 小结

- 四个重要的文件。
    - **links.bin和 bloom_filter.bin，**这两个文件是爬虫自身所用的。
    - **doc_raw.bin 和 doc_id.bin** 是作为搜集阶段的成果，供后面分析、索引、查询用的。

### 分析

- 网页爬取下来后，我们需要对网页进行离线分析。

#### 抽取网页文本信息

1. 依靠 HTML 标签来抽取网页中的文件信息。
    1. 去掉 JavaScript 代码、CSS 格式
    2. 去掉所有的 HTML 标签

#### 分词并创建临时索引

1. 分词
    - 英文网页
        - 通过空格、标点符号等分隔符，将每个单词分割开就可以了。
    - 中文网页
        - 基于字典和规则的分词法
            - 匹配规则，**最长匹配规则**。匹配尽可能长的词语。
            - 实现，将词库中的单词，构建成 Trie 树结构，然后拿网页文本在 Trie 树中匹配。
2. 临时索引
    - 分词完成后，我们得到一组单词列表。
    - 我们把**单词与网页**之间的对应关系，写入到一个临时索引文件中（tmp_index.bin）。这个临时索引文件用来构建倒排索引文件。
    - 文件格式：
        - ![img](imgs/156ee98c0ad5763a082c1f3002d6051e-4931639.jpg)
3. 单词编号文件
    - 我们将**单词跟编号**之间的对应关系，写入到磁盘文件中，并命名为 iterm_id.bin。

#### 小结

1. 两个重要的文件
    - **临时索引文件 tmp_index.bin**
    - **单词编号文件 term_id.bin**

### 索引

1. 将临时索引构建成**倒排索引**。
2. 倒排索引中记录了每个**单词以及包含它的网页列表**。如下图：
    - ![img](imgs/de1f212bc669312a499bbbf2ee3a3734-4932023.jpg)
3. 如何构建倒排索引？
    - ![img](imgs/c91c960472d88233f60d5d4ce6538ee6.jpg)
4. 除了倒排索引文件外，我们还需要一个文件，来记录每个**单词编号在倒排索引文件中的偏移位置**。我们把这个文件命名为 **term_offset.bin**。
    - 这个文件可以帮助我们快速地查找到某个单词编号在倒排索引中存储的位置，进而快速地从倒排索引中读取单词编号对应的网页编号列表。
    - ![img](imgs/deb2fd01ea6f7e1df9da1ad3a8da5854-5016770.jpg)
5. 小结
    - **倒排索引文件 index.bin**
    - **记录单词编号在索引文件中的偏移位置的文件 term_offset.bin** 

### 查询

1. 文件
    - doc_id.bin 记录**网页链接和编号**之间的对应关系
    - term_id.bin 记录**单词和编号**之间的对应关系
    - index.bin 倒排索引文件，记录每个**单词编号以及对应包含它的网页编号列表**
    - term_offset.bin 记录每个单词编号在倒排索引文件中的**偏移位置**
2. 查询过程
    1. 用户在搜索框，输入某个查询文本的时候，我们先用用户输入文本进行**分词**处理。假设，分词后，我们得到 k 个单词。
    2. 我们拿这 k 个单词，去 term_id.bin 对应的散列表中，查找对应的**单词编号**。之后，我们拿到了这个 k 个单词对应的单词编号。
    3. 我们拿这 k 个单词编号，去term_offset.bin 对应的散列表中，查找每个单词编号在倒排索引文件中的**偏移位置**。之后，我们得到了 k 个偏移位置。
    4. 我们拿这 k 个偏移位置，去倒排索引（index.bin）中，查找 k 单词对应的包含它的**网页编号列表**。之后，我们得到了 k 个网页编号列表。
    5. 我们针对这 k 个网页编号列表，**统计每个网页编号出现的次数**。然后，按出现的次数，从小到大排序。出现次数越多，说明包含越多的用户查询单词。
    6. 我们得到一组排好序的网页编号。我们拿着编号，去 doc_id.bin 文件中查找对应的**网页链接**，分页显示给用户就可以了。
